# Результаты лабораторных работ

Ниже представлены результаты выполнения лабораторных работ по задачам классификации, сегментации и обнаружения объектов. Для каждой задачи сравниваются обычные и улучшенные бейзлайн-модели, а также собственные реализации.

## Лабораторная работа №6: Классификация
**Задача**: Классификация изображений (цветы: daisy, dandelion, rose, sunflower, tulip).

| Модель                     | Обычная                              | Улучшенный бейзлайн                     |
|----------------------------|--------------------------------------|-----------------------------------------|
| ResNet50                   | Accuracy: 0.6817, F1-Score: 0.6756   | Accuracy: 0.9039, F1-Score: 0.9034      |
| Vision Transformer (ViT)   | Accuracy: 0.9190, F1-Score: 0.9188   | Accuracy: 0.9248, F1-Score: 0.9247      |
| Собственная имплементация  | Accuracy: 0.6076, F1-Score: 0.6071 (Simple CNN) | Accuracy: 0.6366, F1-Score: 0.6326 (Improved CNN) |

## Лабораторная работа №7: Сегментация
**Задача**: Сегментация изображений (предположительно, медицинских или других данных).

| Модель                     | Обычная                              | Улучшенный бейзлайн                     |
|----------------------------|--------------------------------------|-----------------------------------------|
| UNet                       | -                                    | Accuracy: 0.9961, Dice: 0.9980, IoU: 0.9961 (U-Net++) |
| Собственная имплементация  | Accuracy: 1.0000, Dice: 1.0000, IoU: 1.0000 (SimpleUNet) | - |

## Лабораторная работа №8: Обнаружение объектов
**Задача**: Обнаружение объектов на датасете COCO128.

| Модель                     | Обычная                              | Улучшенный бейзлайн                     |
|----------------------------|--------------------------------------|-----------------------------------------|
| YOLO                       | mAP50: 0.5963, mAP50:95: 0.4417 (YOLOv11n) | mAP50: 0.6964, mAP50:95: 0.5350 (YOLOv11s) |
| Собственная имплементация  | mAP50: 0.0000, mAP50:95: 0.0000 (Custom YOLOv11) | - |

### Выводы
- **Классификация**: Vision Transformer с аугментацией показал лучшие результаты (Accuracy: 0.9248), но ResNet50 с аугментацией (Accuracy: 0.9039) предлагает баланс между производительностью и скоростью. Собственные CNN-модели требуют доработки.
- **Сегментация**: U-Net++ демонстрирует высокую производительность (Dice: 0.9980), тогда как SimpleUNet с идеальными метриками (Dice: 1.0000) требует проверки на переобучение.
- **Обнаружение объектов**: YOLOv11s (mAP50: 0.6964) превосходит YOLOv11n благодаря аугментациям. Кастомная модель YOLOv11 не дала результатов, что указывает на проблемы в реализации.
